Perfect. Below is a **clean, professional, copy-paste-ready `README.md`** for **InterviewFox** that matches your current architecture and GitHub-only state.

You can **replace your README Ø¨Ø§Ù„ÙƒØ§Ù…Ù„** with this.

---

# ðŸ¦Š InterviewFox

**InterviewFox** is a real-time AI interview copilot that helps candidates answer interview questions using their **resume**, **job description**, and **live interviewer questions**.

It is designed as a **candidate-controlled**, **privacy-safe**, and **low-latency** interview assistant.

---

## ðŸš€ What InterviewFox Does

* Lets candidates **upload resume & job description** (PDF / DOCX)
* Captures **interviewer questions in real time** using IC (Interview Capture) mode
* Uses **RAG (Retrieval Augmented Generation)** for personalized answers
* Streams AI-generated answers **word-by-word (typing effect)**
* Works **locally for testing** (no cloud required initially)

---

## ðŸ§  Key Concepts

### IC Mode (Interview Capture)

InterviewFox does **not listen continuously**.

The candidate controls capture using **IC ON / IC OFF**:

* IC ON â†’ mic listens to interviewer
* IC OFF â†’ captured question is finalized
* Answer generation starts immediately

This avoids:

* Speaker confusion
* Ethical/legal issues
* Unnecessary background listening

---

## ðŸ§± Architecture Overview

```
Chrome Extension
 â”œâ”€â”€ Resume / JD Upload
 â”œâ”€â”€ IC ON / OFF (Mic Control)
 â”œâ”€â”€ Live Answer Display (Typing Effect)
 â”‚
FastAPI Backend (Local / Future Cloud)
 â”œâ”€â”€ Session Management
 â”œâ”€â”€ Resume & JD Parsing
 â”œâ”€â”€ RAG (FAISS + Embeddings)
 â”œâ”€â”€ Whisper STT (Local, Testing)
 â”œâ”€â”€ LLM Answer Generation
 â””â”€â”€ WebSocket Streaming
```

---

## ðŸ—‚ï¸ Project Structure

```
interviewfox/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py            # API entrypoint
â”‚   â”‚   â”œâ”€â”€ ws_answer.py       # Streaming answers (WebSocket)
â”‚   â”‚   â”œâ”€â”€ ws_audio.py        # Mic audio input (IC mode)
â”‚   â”‚   â”œâ”€â”€ stt_whisper.py     # Local Whisper STT (testing)
â”‚   â”‚   â”œâ”€â”€ rag.py             # Resume/JD RAG engine
â”‚   â”‚   â”œâ”€â”€ llm_client.py      # LLM integration
â”‚   â”‚   â”œâ”€â”€ files.py           # PDF/DOCX text extraction
â”‚   â”‚   â””â”€â”€ session_store.py   # In-memory session store
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ extension/
â”‚   â”œâ”€â”€ popup.html             # Chrome extension UI
â”‚   â””â”€â”€ popup.js               # IC logic + WebSockets
â”‚
â””â”€â”€ README.md
```

---

## ðŸ“„ Resume & JD Support

Supported formats:

* âœ… PDF
* âœ… DOCX
* âœ… TXT (fallback)

Files are:

* Parsed on upload
* Stored per session
* Used automatically for RAG (no repeated uploads)

---

## ðŸ”Š Audio & STT (Testing Mode)

* Uses **local Whisper (faster-whisper)**
* No cloud STT required for testing
* Mic access is **explicit and user-controlled**
* Audio pipeline is **dormant until backend is run locally**

> âš ï¸ Live mic testing requires running the backend locally
> GitHub alone cannot access microphone or run WebSockets

---

## ðŸ” Security & Privacy

* No API keys committed to GitHub
* `.env.example` contains placeholders only
* Resume/JD data stored **in-memory (MVP)**
* IC mode prevents continuous listening

---

## ðŸ§ª Current Status

* âœ… Backend architecture complete
* âœ… Chrome extension UI complete
* âœ… IC mode implemented
* âœ… RAG + streaming answers implemented
* â³ Local testing (Whisper) pending
* â³ Cloud deployment optional (future)

---

## ðŸ›£ï¸ Roadmap

* [ ] Hotkey-based IC control
* [ ] Better question boundary detection
* [ ] Session persistence (Redis / DB)
* [ ] Cloud STT (Deepgram / Azure Speech)
* [ ] Pricing & usage limits
* [ ] Production deployment

---

## ðŸ§  One-Line Description (for demos)

> **InterviewFox is a real-time AI interview copilot that captures interviewer questions on demand and streams personalized answers using your resume and job description.**
